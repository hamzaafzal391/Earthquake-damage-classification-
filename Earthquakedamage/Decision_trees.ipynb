{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lwwmIFbNe0Q"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from category_encoders import OrdinalEncoder\n",
        "from IPython.display import VimeoVideo\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wrangle(db_path):\n",
        "    # Connect to database\n",
        "    conn = sqlite3.connect(db_path)\n",
        "\n",
        "    # Construct query\n",
        "    query = \"\"\"\n",
        "        SELECT distinct(i.building_id) AS b_id,\n",
        "           s.*,\n",
        "           d.damage_grade\n",
        "        FROM id_map AS i\n",
        "        JOIN building_structure AS s ON i.building_id = s.building_id\n",
        "        JOIN building_damage AS d ON i.building_id = d.building_id\n",
        "        WHERE district_id = 4\n",
        "    \"\"\"\n",
        "\n",
        "    # Read query results into DataFrame\n",
        "    df = pd.read_sql(query, conn, index_col=\"b_id\")\n",
        "\n",
        "    # Identify leaky columns\n",
        "    drop_cols = [col for col in df.columns if \"post_eq\" in col]\n",
        "\n",
        "    # Add high-cardinality / redundant column\n",
        "    drop_cols.append(\"building_id\")\n",
        "\n",
        "    # Create binary target column\n",
        "    df[\"damage_grade\"] = df[\"damage_grade\"].str[-1].astype(int)\n",
        "    df[\"severe_damage\"] = (df[\"damage_grade\"] > 3).astype(int)\n",
        "\n",
        "    # Drop old target\n",
        "    drop_cols.append(\"damage_grade\")\n",
        "\n",
        "    # Drop multicollinearity column\n",
        "    drop_cols.append(\"count_floors_pre_eq\")\n",
        "\n",
        "    # Drop columns\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "nuvQeZfBNopL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = wrangle(\"/home/jovyan/nepal.sqlite\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5uIW5LfoNrcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"severe_damage\"\n",
        "X=df.drop(columns='severe_damage')\n",
        "y = df[target]"
      ],
      "metadata": {
        "id": "656TiNGwNtT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "QYQGfh2MNvTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "VR01_hrsNx2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_baseline = y_train.value_counts(normalize=True).max()\n",
        "print(\"Baseline Accuracy:\", round(acc_baseline, 2))"
      ],
      "metadata": {
        "id": "nYz_kW2cNzSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Model\n",
        "model = make_pipeline(\n",
        "OrdinalEncoder(),\n",
        "DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "# Fit model to training data\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "dbtR-Lv3N0sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train = accuracy_score(y_train,model.predict(X_train))\n",
        "acc_val = model.score(X_val,y_val)\n",
        "\n",
        "print(\"Training Accuracy:\", round(acc_train, 2))\n",
        "print(\"Validation Accuracy:\", round(acc_val, 2))"
      ],
      "metadata": {
        "id": "fAi6ygZYN2sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_depth = model.named_steps[\"decisiontreeclassifier\"].get_depth()\n",
        "print(\"Tree Depth:\", tree_depth)"
      ],
      "metadata": {
        "id": "lvDIQqeLN4AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depth_hyperparams = range(1,50,2)"
      ],
      "metadata": {
        "id": "3Y7nwS_gN5Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty lists for training and validation accuracy scores\n",
        "training_acc = []\n",
        "validation_acc = []\n",
        "\n",
        "for d in depth_hyperparams:\n",
        "    # Create model with `max_depth` of `d`\n",
        "    test_model = make_pipeline(\n",
        "        OrdinalEncoder(),\n",
        "        DecisionTreeClassifier(max_depth=d,random_state=42)\n",
        "    )    # Fit model to training data\n",
        "    test_model.fit(X_train, y_train)\n",
        "    # Calculate training accuracy score and append to `training_acc`\n",
        "    training_acc.append(accuracy_score(y_train,test_model.predict(X_train)))\n",
        "    # Calculate validation accuracy score and append to `training_acc`\n",
        "    validation_acc.append(accuracy_score(y_val,test_model.predict(X_val)))\n",
        "\n",
        "print(\"Training Accuracy Scores:\", training_acc[:3])\n",
        "print(\"Validation Accuracy Scores:\", validation_acc[:3])"
      ],
      "metadata": {
        "id": "g7XFKe5nN651"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot `depth_hyperparams`, `training_acc`\n",
        "plt.plot(depth_hyperparams,training_acc, label='Training_acc');\n",
        "plt.plot(depth_hyperparams,validation_acc, label='Test_acc');\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel(\"Accuracy score\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "FEvO2E2jN8my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=make_pipeline(OrdinalEncoder(),DecisionTreeClassifier(max_depth=6,random_state=42)).fit(X_train,y_train)\n",
        "test_acc = accuracy_score(y_test,model.predict(X_test))\n",
        "print(\"Test Accuracy:\", round(test_acc, 2))"
      ],
      "metadata": {
        "id": "YfgWNdgjN-QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create larger figure\n",
        "fig, ax = plt.subplots(figsize=(25, 12))\n",
        "# Plot tree\n",
        "plot_tree(\n",
        "    decision_tree=model.named_steps['decisiontreeclassifier'],\n",
        "    feature_names=X_train.columns.to_list(),\n",
        "    filled=True,  # Color leaf with class\n",
        "    rounded=True,  # Round leaf edges\n",
        "    proportion=True,  # Display proportion of classes in leaf\n",
        "    max_depth=3,  # Only display first 3 levels\n",
        "    fontsize=12,  # Enlarge font\n",
        "    ax=ax,  # Place in figure axis\n",
        ");"
      ],
      "metadata": {
        "id": "v-JkAoc3N_kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = X_train.columns.to_list()\n",
        "importances = model.named_steps['decisiontreeclassifier'].feature_importances_\n",
        "\n",
        "print(\"Features:\", features[:3])\n",
        "print(\"Importances:\", importances[:3])"
      ],
      "metadata": {
        "id": "53skuQrOOBLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_imp = pd.Series(importances,index=features).sort_values()\n",
        "feat_imp.head()"
      ],
      "metadata": {
        "id": "4WCOkq2WOECw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create horizontal bar chart\n",
        "feat_imp.plot(kind='barh')\n",
        "plt.xlabel(\"Gini Importance\");"
      ],
      "metadata": {
        "id": "0I4V5-MtOFxO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}